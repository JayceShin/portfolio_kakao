{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold, train_test_split\r\n",
        "import xgboost\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from imblearn.under_sampling import *\r\n",
        "from imblearn.over_sampling import *\r\n",
        "from imblearn.combine import *\r\n",
        "from sklearn.metrics import classification_report, explained_variance_score\r\n",
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from datetime import datetime, date"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1632537768558
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('./data/pre_data.csv')\r\n",
        "dataset"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "              0         1  2  3  4    5    6    7    8    9  ...  338  339  \\\n0      0.214297  0.236965  4  2  3  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n1      2.449873  2.551062  6  0  1  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n2      0.248730  0.272536  4  2  3  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n3     -0.093402 -0.081406  0  1  1  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n4      0.298192  0.324030  3  1  1  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n...         ...       ... .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n37209 -0.289216 -0.283953  2  2  2  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n37210 -0.301264 -0.296447  1  2  1  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n37211 -0.298253 -0.293311  0  2  1  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n37212 -0.301264 -0.296447  0  2  1  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n37213 -0.295238 -0.290224  3  1  1  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n\n       340  341  342  343  344  345  346  0.1  \n0      0.0  0.0  0.0  0.0  0.0  1.0  0.0    4  \n1      0.0  0.0  0.0  0.0  0.0  1.0  0.0    4  \n2      0.0  0.0  0.0  0.0  0.0  1.0  0.0    4  \n3      0.0  0.0  0.0  0.0  0.0  1.0  0.0    1  \n4      0.0  0.0  0.0  0.0  0.0  1.0  0.0    4  \n...    ...  ...  ...  ...  ...  ...  ...  ...  \n37209  0.0  0.0  0.0  0.0  0.0  0.0  0.0   12  \n37210  0.0  0.0  0.0  0.0  0.0  0.0  0.0   12  \n37211  0.0  0.0  0.0  0.0  0.0  0.0  0.0   12  \n37212  0.0  0.0  0.0  0.0  0.0  0.0  0.0   12  \n37213  0.0  0.0  0.0  0.0  0.0  0.0  0.0   12  \n\n[37214 rows x 348 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>338</th>\n      <th>339</th>\n      <th>340</th>\n      <th>341</th>\n      <th>342</th>\n      <th>343</th>\n      <th>344</th>\n      <th>345</th>\n      <th>346</th>\n      <th>0.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.214297</td>\n      <td>0.236965</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.449873</td>\n      <td>2.551062</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.248730</td>\n      <td>0.272536</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.093402</td>\n      <td>-0.081406</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.298192</td>\n      <td>0.324030</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37209</th>\n      <td>-0.289216</td>\n      <td>-0.283953</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>37210</th>\n      <td>-0.301264</td>\n      <td>-0.296447</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>37211</th>\n      <td>-0.298253</td>\n      <td>-0.293311</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>37212</th>\n      <td>-0.301264</td>\n      <td>-0.296447</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>37213</th>\n      <td>-0.295238</td>\n      <td>-0.290224</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n<p>37214 rows Ã— 348 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632537209758
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:,:-1]\r\n",
        "y = dataset.iloc[:,-1:]\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632537665676
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='multi:softmax',\r\n",
        "                    silent=True, nthread=1)\r\n",
        "\r\n",
        "def timer(start_time=None):\r\n",
        "    if not start_time:\r\n",
        "        start_time = datetime.now()\r\n",
        "        return start_time\r\n",
        "    elif start_time:\r\n",
        "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\r\n",
        "        tmin, tsec = divmod(temp_sec, 60)\r\n",
        "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\r\n",
        "        \r\n",
        "params = {\r\n",
        "        'min_child_weight': [1, 5, 10],\r\n",
        "        'gamma': [0.5, 1, 1.5, 2, 5],\r\n",
        "        'subsample': [0.6, 0.8, 1.0],\r\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\r\n",
        "        'max_depth': [3, 4, 5]\r\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632537775245
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds = 3\r\n",
        "param_comb = 5\r\n",
        "\r\n",
        "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\r\n",
        "\r\n",
        "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='f1_micro', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001, return_train_score=bool )\r\n",
        "\r\n",
        "start_time = timer(None)\r\n",
        "random_search.fit(X_train,y_train)\r\n",
        "timer(start_time)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n\n Time taken: 2 hours 13 minutes and 58.39 seconds.\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632545820729
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n All results:')\r\n",
        "print(random_search.cv_results_)\r\n",
        "print('\\n Best estimator:')\r\n",
        "print(random_search.best_estimator_)\r\n",
        "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\r\n",
        "print(random_search.best_score_ * 2 - 1)\r\n",
        "print('\\n Best hyperparameters:')\r\n",
        "print(random_search.best_params_)\r\n",
        "results = pd.DataFrame(random_search.cv_results_)\r\n",
        "results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n All results:\n{'mean_fit_time': array([1285.3579487 , 1829.08356524, 1477.58274937, 1000.55258155,\n       1437.14624103]), 'std_fit_time': array([  9.8153772 , 154.16060519,  31.12361144,   4.1713108 ,\n        14.33242706]), 'mean_score_time': array([6.56061037, 7.13333702, 7.17541337, 5.69769979, 5.13933317]), 'std_score_time': array([0.13288017, 0.64135533, 0.34474525, 0.34586884, 0.39874882]), 'param_subsample': masked_array(data=[1.0, 0.6, 0.8, 1.0, 0.8],\n             mask=[False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'param_min_child_weight': masked_array(data=[5, 1, 5, 5, 1],\n             mask=[False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'param_max_depth': masked_array(data=[3, 5, 5, 5, 4],\n             mask=[False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'param_gamma': masked_array(data=[5, 1.5, 1, 5, 1],\n             mask=[False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'param_colsample_bytree': masked_array(data=[1.0, 0.8, 0.8, 0.6, 1.0],\n             mask=[False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'params': [{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 3, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 1, 'colsample_bytree': 1.0}], 'split0_test_score': array([0.60113929, 0.6544497 , 0.64316423, 0.62575236, 0.64026225]), 'split1_test_score': array([0.60206385, 0.65140277, 0.64441578, 0.62689455, 0.6426959 ]), 'split2_test_score': array([0.60668602, 0.65505751, 0.64495324, 0.62388477, 0.64215844]), 'mean_test_score': array([0.60329639, 0.65363666, 0.64417775, 0.62551056, 0.64170553]), 'std_test_score': array([0.00242637, 0.00159897, 0.0007495 , 0.00124058, 0.00104387]), 'rank_test_score': array([5, 1, 2, 4, 3], dtype=int32), 'split0_train_score': array([0.61211437, 0.69509836, 0.68053316, 0.64403956, 0.67370741]), 'split1_train_score': array([0.61202773, 0.69618961, 0.68173268, 0.64663836, 0.67431612]), 'split2_train_score': array([0.61589724, 0.69538346, 0.68017413, 0.64368249, 0.67216639]), 'mean_train_score': array([0.61334645, 0.69555714, 0.68081332, 0.6447868 , 0.67339664]), 'std_train_score': array([0.00180403, 0.00046212, 0.0006664 , 0.00131734, 0.00090472])}\n\n Best estimator:\nXGBClassifier(colsample_bytree=0.8, gamma=1.5, learning_rate=0.02, max_depth=5,\n              n_estimators=600, nthread=1, objective='multi:softprob',\n              silent=True, subsample=0.6)\n\n Best normalized gini score for 3-fold search with 5 parameter combinations:\n0.3072733204558349\n\n Best hyperparameters:\n{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632545823169
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = XGBClassifier(colsample_bytree=0.8, gamma=1.5, learning_rate=0.02, max_depth=5,\r\n",
        "              n_estimators=600, nthread=1, objective='multi:softprob',\r\n",
        "              silent=True, subsample=0.6)"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632548541910
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# basic\r\n",
        "\r\n",
        "pred = xgb.fit(X_train, y_train).predict(X_test)\r\n",
        "print(classification_report(y_test, pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.59      0.80      0.68      2957\n           1       0.77      0.54      0.63      2351\n           2       0.78      0.17      0.27        42\n           3       0.57      0.66      0.61        32\n           4       0.74      0.45      0.56       340\n           5       0.70      0.60      0.65       500\n           6       0.88      0.28      0.42       104\n           7       0.94      0.84      0.89       100\n           8       0.59      0.48      0.53       947\n           9       0.77      0.87      0.81      1235\n          10       0.56      0.63      0.59       314\n          11       0.60      0.36      0.45       211\n          12       0.96      0.87      0.91       171\n\n    accuracy                           0.66      9304\n   macro avg       0.73      0.58      0.62      9304\nweighted avg       0.68      0.66      0.66      9304\n\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632551078039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#under sample\r\n",
        "X_under, y_under = RandomUnderSampler(random_state=0).fit_resample(X_train, y_train)\r\n",
        "y_under.value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "0.1\n12     100\n11     100\n10     100\n9      100\n8      100\n7      100\n6      100\n5      100\n4      100\n3      100\n2      100\n1      100\n0      100\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632551511510
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_unsam = xgb.fit(X_under, y_under).predict(X_test)\r\n",
        "print(classification_report(y_test, pred_unsam))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.62      0.28      0.39      2957\n           1       0.63      0.42      0.50      2351\n           2       0.06      0.64      0.10        42\n           3       0.13      0.84      0.22        32\n           4       0.27      0.55      0.37       340\n           5       0.46      0.59      0.51       500\n           6       0.11      0.47      0.18       104\n           7       0.48      0.86      0.61       100\n           8       0.37      0.46      0.41       947\n           9       0.79      0.55      0.65      1235\n          10       0.34      0.70      0.46       314\n          11       0.19      0.74      0.31       211\n          12       0.55      0.84      0.67       171\n\n    accuracy                           0.44      9304\n   macro avg       0.38      0.61      0.41      9304\nweighted avg       0.57      0.44      0.46      9304\n\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632551664650
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# over sample\r\n",
        "X_samp_smote, y_samp_smote = SMOTE(random_state=4).fit_resample(X_train, y_train)\r\n",
        "y_samp_smote.value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "0.1\n12     8807\n11     8807\n10     8807\n9      8807\n8      8807\n7      8807\n6      8807\n5      8807\n4      8807\n3      8807\n2      8807\n1      8807\n0      8807\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632556966897
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_over = xgb.fit(X_samp_smote, y_samp_smote).predict(X_test)\r\n",
        "print(classification_report(y_test, pred_over))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.70      0.50      0.59      2957\n           1       0.72      0.55      0.62      2351\n           2       0.08      0.60      0.14        42\n           3       0.31      0.88      0.46        32\n           4       0.52      0.59      0.56       340\n           5       0.56      0.69      0.62       500\n           6       0.24      0.58      0.34       104\n           7       0.75      0.92      0.83       100\n           8       0.50      0.60      0.54       947\n           9       0.82      0.77      0.79      1235\n          10       0.39      0.82      0.53       314\n          11       0.32      0.75      0.45       211\n          12       0.90      0.88      0.89       171\n\n    accuracy                           0.60      9304\n   macro avg       0.53      0.70      0.57      9304\nweighted avg       0.66      0.60      0.62      9304\n\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632566492104
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}