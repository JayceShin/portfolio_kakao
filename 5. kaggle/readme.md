## Kaggle

    â­ ì‚¬ë‚´ ìºê¸€ëŒ€íšŒì— ì°¸ì—¬í•˜ì—¬ ì´ 38íŒ€ ì¤‘ 2ë“±ì„ ìˆ˜ìƒí•˜ì˜€ìŠµë‹ˆë‹¤.
    
![ìºê¸€_ìˆœìœ„](https://user-images.githubusercontent.com/31294995/134780170-ec38e969-0c0b-4b86-9b70-c84012fe6109.PNG)

ğŸ“– **ëª©ì°¨**

[1. EDA](#1-EDA)

[2. ë°ì´í„° ì „ì²˜ë¦¬](#2-ë°ì´í„°-ì „ì²˜ë¦¬)

[3. ëª¨ë¸ë§](#3-ëª¨ë¸ë§)

[4. ìˆ˜í–‰ ê²°ê³¼](#4-ìˆ˜í–‰-ê²°ê³¼)
***
## 1 EDA

### Class Imbalanced

    ë°ì´í„° ë¶„í¬ í™•ì¸ì„ í†µí•´ Class Imbalanceì„ì„ íŒŒì•…í•˜ì˜€ìŠµë‹ˆë‹¤.   
    
![ìºê¸€_ì„ë°¸ëŸ°ìŠ¤](https://user-images.githubusercontent.com/31294995/134780171-acf6d445-93cb-4b7a-8002-6247a4f444d5.PNG)

***
## 2 ë°ì´í„° ì „ì²˜ë¦¬

### Category Encoding

    Labelì´ ì´ 5ê°œì˜ ì¹´í…Œê³ ë¦¬ë¡œ êµ¬ì„±ë˜ì—ˆê¸°ì— intí˜•ìœ¼ë¡œ ì¸ì½”ë”©í•˜ì˜€ìŠµë‹ˆë‹¤.   

Encoding
```python
# Train Dataì˜ Categoryë¥¼ ìˆ«ìí˜• ë°ì´í„°ë¡œ ë³€í™˜
for i in range(len(train_data['Category'])):
    if(train_data['Category'][i] == 'N'):
        train_data['Category'][i] = 0
    elif(train_data['Category'][i] == 'S'):
        train_data['Category'][i] = 1
    elif(train_data['Category'][i] == 'V'):
        train_data['Category'][i] = 2
    elif(train_data['Category'][i] == 'F'):
        train_data['Category'][i] = 3
    elif(train_data['Category'][i] == 'Q'):
        train_data['Category'][i] = 4
```

### OverSampling

    EDA ê³¼ì •ì„ í†µí•´ Imbalanced Dataì„ì„ í™•ì¸í•˜ì˜€ìœ¼ë¯€ë¡œ OverSamplingì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.   

OverSampling
```python
# Oversamplingì„ ìœ„í•´ ê°€ì¥ í° í´ë˜ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê° í´ë˜ìŠ¤ë³„ ë°˜ë³µìˆ˜ë¥¼ ì„¤ì •
con = train_data.sample(frac=1, axis=0)
val = con.values

x = val[:,1:]
y = val[:,0].astype(int)

x_temp = []
count_temp = []

for label in range(5):
    x_i = x[y == label]
    x_temp.append(x_i)
    count_temp.append(len(x_i))
    
counts = (np.floor(max(count_temp) / np.array(count_temp))).astype(int)

# ë°˜ë³µ ìˆ˜ ë§Œí¼ ë°ì´í„°ë¥¼ ëŠ˜ë¦¬ëŠ” Oversampling ì ìš©

for label in range(5):
    count = counts[label]
    if label == 0:
        x_bal = x_temp[label]
        y_bal = np.zeros((count_temp[label])).astype(int)
        count -= 1

    for j in range(count):
        x_bal = np.concatenate((x_bal, x_temp[label]), axis=0)
        y_bal = np.concatenate((y_bal, np.zeros((count_temp[label])).astype(int) + label))
```

***
## 3 ëª¨ë¸ë§

    ë¶„ë¥˜ë¬¸ì œì´ë©° ì‹œí€€ìŠ¤ ë°ì´í„°ì´ê¸° ë•Œë¬¸ì— 1D CNNì„ í†µí•´ ë¶„ë¥˜ê¸°ë¥¼ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.   

ë„¤íŠ¸ì›Œí¬ êµ¬ì„±(Keras)   

```python
# CNN ëª¨ë¸ ì •ì˜

def network(X_train,y_train,X_test,y_test):
    
    im_shape=(X_train.shape[1],1)
    inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')
    
    conv1_1=Convolution1D(64, (6), activation='relu', input_shape=im_shape)(inputs_cnn)
    conv1_1=BatchNormalization()(conv1_1)
    pool1=MaxPool1D(pool_size=(3), strides=(2), padding="same")(conv1_1)
    
    conv2_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool1)
    conv2_1=BatchNormalization()(conv2_1)
    pool2=MaxPool1D(pool_size=(2), strides=(2), padding="same")(conv2_1)
    
    conv3_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool2)
    conv3_1=BatchNormalization()(conv3_1)
    pool3=MaxPool1D(pool_size=(2), strides=(2), padding="same")(conv3_1)

    flatten=Flatten()(pool3)
    
    dense_end1 = Dense(64, activation='relu')(flatten)
    dense_end2 = Dense(32, activation='relu')(dense_end1)
    main_output = Dense(5, activation='softmax', name='main_output')(dense_end2)
    
    model = Model(inputs= inputs_cnn, outputs=main_output)
    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])
    
    callbacks = [EarlyStopping(monitor='val_loss', patience=8),
             ModelCheckpoint(filepath='best_model.h6', monitor='val_loss', save_best_only=True)]

    history=model.fit(X_train, y_train,epochs=100,callbacks=callbacks, batch_size=128,validation_data=(X_test,y_test))
    model.load_weights('best_model.h6')
    return(model,history)
```

***
## 4 ìˆ˜í–‰ ê²°ê³¼

train vs val Accuracy & Loss  
![ìºê¸€_ë¡œìŠ¤](https://user-images.githubusercontent.com/31294995/134780172-2df0071f-5848-40a5-b1f7-2ce0b2d06454.PNG)

***
