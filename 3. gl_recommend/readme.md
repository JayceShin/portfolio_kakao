# íšŒê³„ê³„ì • ì¶”ì²œ

    â­ íšŒê³„ ì›¹ í¬íƒˆ e-Accountingì„ ìš´ì˜í•˜ë©° ì‚¬ìš©ì ì˜¤ë¥˜ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ì „í‘œ ì¬ì²˜ë¦¬ê±´ì„ ì¤„ì´ê³ ì í•´ë‹¹ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ“– **ëª©ì°¨**

[1. í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)

[2. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬](#2-ë°ì´í„°-ìˆ˜ì§‘-ë°-ì „ì²˜ë¦¬)

[3. ëª¨ë¸ë§](#3-ëª¨ë¸ë§)

[4. ìˆ˜í–‰ ê²°ê³¼](#4-ìˆ˜í–‰-ê²°ê³¼)
***
## 1 í”„ë¡œì íŠ¸ ê°œìš”

### ë°°ê²½

ìµœê·¼ ê¸°ì—…ì€ ë‹¨ìˆœì—…ë¬´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¸ë ¥ë“¤ì˜ ë¹„ì¤‘ì„ ê°ì†Œí•˜ëŠ” ê²ƒì— í¬ì»¤ìŠ¤ë¥¼ ë§ì¶”ì–´ ì´ë¥¼ ê¸°ì—… ì´ìµì—ê¹Œì§€ ì—°ê²°ì‹œí‚¤ê³  ìˆëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤. 
ëŒ€í‘œì ìœ¼ë¡œ ë²•ì¸ì¹´ë“œ, ì„¸ê¸ˆê³„ì‚°ì„œ ë“± íšŒê³„ ì „í‘œì²˜ë¦¬ë¥¼ ê¸°ì¡´ì—ëŠ” ì„œë¬´ë“¤ì´ í–ˆë‹¤ë©´ ìµœê·¼ì—ëŠ” ë³¸ì¸ì´ ì‚¬ìš©í•œ ë‚´ì—­ì€ ë³¸ì¸ì´ ì²˜ë¦¬í•˜ëŠ” ì‚¬ë‚´ ì œë„ë“¤ì´ ì—¬ëŸ¬ ê¸°ì—…ì—ì„œ ë§Œë“¤ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤. 
í•˜ì§€ë§Œ íšŒê³„ ì²˜ë¦¬ì— ëŒ€í•œ ì§€ì‹ì´ ì—†ë‹¤ë©´ ì „í‘œ ì‘ì„±ì‹œ ì„ íƒí•´ì•¼í•  íšŒê³„ ê³„ì •ë“¤ì— ëŒ€í•´ ìƒì†Œí•  ê²ƒì´ê³ , ì „í‘œë¥¼ ê¸°í•œë‚´ì— ì²˜ë¦¬í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì‚¬ì†Œí•˜ì§€ë§Œ ì´ì— ëŒ€í•œ ë¶€ë‹´ì€ ë³¸ì¸ì˜ ì—…ë¬´ì—ê¹Œì§€ ì˜í–¥ì„ ë¯¸ì¹˜ê²Œ ë©ë‹ˆë‹¤.   
ë˜í•œ íšŒê³„íŒ€ì€ ì›”ë§ˆê°ì‹œ ì „í‘œë¥¼ ì¼ì¼íˆ ê²€ìˆ˜í•˜ì—¬ ì˜ëª» ì²˜ë¦¬ëœ ì „í‘œë“¤ì„ ë°˜ë ¤í•˜ê³  ì²˜ë¦¬ìì—ê²Œ ì¬ì²˜ë¦¬ìš”ì²­ì„ ë³´ë‚´ì•¼ í•˜ê¸°ì— ë‹¨ìˆœ ì—…ë¬´ì˜ ì˜í–¥ë„ê°€ ì»¤ì§€ê²Œ ë©ë‹ˆë‹¤.
ë”°ë¼ì„œ ì´ë¥¼ ì „í‘œ ì²˜ë¦¬ì‹œ íšŒê³„ ê³„ì • ê³¼ëª© ì¶”ì²œì„ í†µí•´ ê°œì„ í•˜ê³ ì í•©ë‹ˆë‹¤.

### ëª©í‘œ

    ì „í‘œ ì‘ì„±ì‹œ íšŒê³„ ê³„ì •ì„ ì •í™•ë„ ìˆœìœ¼ë¡œ ì¶”ì²œí•˜ì—¬ ë‹¨ìˆœì—…ë¬´ì˜ ë¶€ë‹´ì„ ì¤„ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì˜€ìŠµë‹ˆë‹¤.

***
## 2 ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬

### ë°ì´í„° ìˆ˜ì§‘

    íšŒê³„ ì „í‘œì²˜ë¦¬ DBì—ì„œ ìµœê·¼ 3ë…„ì˜ ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ë° ì „í‘œì— ëŒ€í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì˜€ìŠµë‹ˆë‹¤.   
    ë°ì´í„° ìˆ˜ì§‘ì‹œ ìƒìœ„ 10ê°œì˜ ê³„ì •ì½”ë“œê°€ ì „ì²´ 90%ì˜ ë¶„í¬ë¥¼ ì°¨ì§€í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” sparseí•˜ê²Œ ë‚˜íƒ€ë‚¬ê¸°ì—   
    10ê°œì˜ ê³„ì •ì½”ë“œë§Œì„ ëŒ€ìƒìœ¼ë¡œ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

![íšŒê³„_ë°ì´í„°](https://user-images.githubusercontent.com/31294995/134773991-00d80d96-068e-467e-9c82-85a88037f627.PNG)

### ì „ì²˜ë¦¬

    Null Data ë° ì‹œê°„ ë°ì´í„°ì— ëŒ€í•´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

1. ì—…ì¢…ì½”ë“œ   
ì—…ì¢…ì½”ë“œê°€ ë¹ˆ ê²½ìš°ë¥¼ ì‚´í´ë³´ì•˜ì„ ë•Œ ìì‚¬ ë°±í™”ì ì—ì„œ ì‚¬ìš©í•œ ê²½ìš°ì˜€ìœ¼ë©°, ìì‚¬ ë°±í™”ì ì—ì„œëŠ” ë²•ì¸ì¹´ë“œë¥¼ ì‹ë‹¹ë§Œ ì´ìš©í•  ìˆ˜ ìˆê¸°ì— ë¹ˆ ê°’ì„ ì¼ë°˜ ì‹ë‹¹ìœ¼ë¡œ ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. 
ì„¸ë¶€ ì‹ë‹¹ ì¢…ë¥˜ì˜ ì½”ë“œë“¤ì— ëŒ€í•´ì„œëŠ” ì •í•´ì£¼ì§€ ì•Šì•˜ì§€ë§Œ ì‹ë‹¹ì—ì„œ ì‚¬ìš©í•œ ë‚´ì—­ì€ íšŒê³„ì „í‘œë¡œ ê·€ê²°ë  ë•Œ ëŒ€ë¶€ë¶„ì´ ì—…ë¬´ì‹œì‹ëŒ€ ê³„ì •ìœ¼ë¡œ ë§¤í•‘ë˜ê¸°ì— ë¬¸ì œê°€ ì—†ì„ ê²ƒì´ë¼ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤. 

2. ì‚¬ìš©ì²˜   
ì‚¬ìš©ì²˜ì— ëŒ€í•œ ë‚´ì—­ì— ë‹¤ìˆ˜ì˜ ë¹ˆ ê°’ë“¤ì´ ì¡´ì¬í•¨ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” í•´ì™¸ ì‚¬ìš©ë¶„ìœ¼ë¡œì¨ í•´ì™¸ì˜ ì‚¬ì—…ìë²ˆí˜¸ê°€ ì‚¬ìš©ë‚´ì—­ìœ¼ë¡œ 0000000000ê³¼ ê°™ì´ ë¶ˆë¶„ëª…í•˜ê²Œ ë“¤ì–´ì˜¤ê¸°ì— ì‚¬ìš©ì²˜ì— ëŒ€í•œ ì •ë³´ê°€ ë¹ˆ ê°’ìœ¼ë¡œ ì±„ì›Œì§€ê²Œ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ í•´ë‹¹ ì‚¬ì—…ìë²ˆí˜¸ê°€ 000000000ìœ¼ë¡œ ë˜ì–´ìˆëŠ” ì‚¬ìš©ì²˜ì— ëŒ€í•œ ì •ë³´ë“¤ì„ ì„ì˜ì˜ Foreignì´ë¼ëŠ” ë³€ìˆ˜ë¡œ ì²˜ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.

3. ì‚¬ìš©ì¼/ ì‚¬ìš©ì‹œê°„   
ì‚¬ìš©ë‚´ì—­ì—ëŠ” ì‚¬ìš©ì¼, ì‚¬ìš© ì‹œê°„ì— ëŒ€í•œ ì •ë³´ë“¤ì´ ë“¤ì–´ìˆìŠµë‹ˆë‹¤. 
ì´ë¥¼ í™œìš©í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì‹œê°„ì´ ì „í‘œ ê³„ì •ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ íŒŒì•…í•´ë³´ì•˜ê³ , ëª‡ ê°€ì§€ íŠ¹ì§•ì„ ì¶”ë ¤ë‚¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 
ê°€ì¥ ê°•í•œ íŠ¹ì§•ì€ ì‚¬ìš© ì‹œê°„ì— ë”°ë¼ íŠ¹ì • ê³„ì •ì´ ë§ì´ ì‚¬ìš©ëœë‹¤ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤. 
ì£¼ë¡œ ì ì‹¬, ì €ë… ë“±ì˜ ì‹œê°„ì— ì‚¬ìš©ë˜ë©´ ì—…ë¬´ì‹œì‹ëŒ€, ì €ë… ì´í›„ì‹œê°„ì—ëŠ” ì ‘ëŒ€ë¹„ ê·¸ë¦¬ê³  ì´ì™¸ ì‚¬ìš©ì‹œê°„ì—ëŠ” ì‚¬ë¬´ì— ê´€ë ¨ëœ ê³„ì •ë“¤ì´ ì‚¬ìš©ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 
ë”°ë¼ì„œ ì‹œê°„ëŒ€ë¥¼ ì´ 6ë¶„ë¥˜í•˜ì—¬ í•´ë‹¹ ì‹œê°„ë§ˆë‹¤ labelingì„ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ì‚¬ìš©ì¼ì´ ë§ì¼ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ ì—¬ëŸ¬ ê³µê³¼ê¸ˆ ê³„ì •ì— ëŒ€í•œ ë¹„ìš©ê³„ì •ì´ ì‚¬ìš©ë˜ëŠ” ë¹ˆë„ê°€ ë†’ì•„ì§ˆ ê²ƒì´ë¼ íŒë‹¨í•˜ì˜€ìœ¼ë¯€ë¡œ ì‚¬ìš©ì¼ ë˜í•œ 3ë¶„ë¥˜í•˜ì—¬ labelingì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

4. ê¸ˆì•¡    
ê¸ˆì•¡ì€ ì‚¬ìš©ê¸ˆì•¡, ë¶€ê°€ì„¸ë¡œ ë‚˜ëˆ„ì–´ì§€ë©° ë‹¤ë¥¸ ì¸ì½”ë”©ëœ ë°ì´í„°ë“¤ë³´ë‹¤ ë‹¨ìœ„ê°€ í¬ê¸° ë•Œë¬¸ì— StandardScalerë¡œ ì¡°ì •í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” í‰ê·  0 , ë¶„ì‚° 1ë¡œ ì¡°ì •í•˜ëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.

5. ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜   
ìˆ˜ì§‘í•œ ë°ì´í„°ëŠ” ëŒ€ë¶€ë¶„ì´ ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ì˜€ìŠµë‹ˆë‹¤. ì´ë¥¼ í™œìš©í•˜ê¸° ìœ„í•´ ì¸ì½”ë”© ê³¼ì •ì´ í•„ìš”í–ˆìœ¼ë¯€ë¡œ ê° ëª¨ë¸ì˜ íŠ¹ì„±ì— ë§ì¶”ì–´ one-hot ë˜ëŠ” label ì¸ì½”ë”©ì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.   
Tree ëª¨ë¸ì—ì„œëŠ” label Encodingì„ í•˜ì˜€ê³  Network ëª¨ë¸ì—ì„œëŠ” one-hot Encodingì„ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.

***
## 3 ëª¨ë¸ë§

    MLê³¼ NN ë°©ì‹ì„ í†µí•´ ëª¨ë¸ì„ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

### 3.1 Machine Learning   

    ML ë°©ì‹ìœ¼ë¡œëŠ” Random Forestì™€ XGBClassifierë¥¼ ì‚¬ìš©í•´ ë¶„ë¥˜ê¸°ë¥¼ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

1. RandomizerSerach & K-fold    
ìµœì  íŒŒë¼ë¯¸í„°ê°’ì„ ì°¾ê¸° ìœ„í•´ RandomizerSearchë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë“  ì¡°í•©ì„ ì°¾ëŠ” GridSearchë³´ë‹¤ ì„±ëŠ¥ì€ ë–¨ì–´ì§ˆì§€ ëª°ë¼ë„ ì¡°í•©ì„ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œí•˜ëŠ” RandomizerSearchê°€ ì‹œê°„ ë©´ì—ì„œ íš¨ìœ¨ì ì´ë¼ê³  íŒë‹¨í•˜ì˜€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë˜í•œ ê²€ì¦ì„ ìœ„í•´ 3 foldë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

![íšŒê³„_grid](https://user-images.githubusercontent.com/31294995/134774544-069449ee-868d-4b55-b3da-29a90b5cb1b4.PNG)
ref <https://medium.com/@peterworcester_29377/a-comparison-of-grid-search-and-randomized-search-using-scikit-learn-29823179bc85>

2. Sampling(Under/ Over)   
ë°ì´í„° ë¶„í¬ë¥¼ ì‚´í´ë³´ì•˜ì„ë•Œ ì•„ë˜ì™€ ê°™ì´ ë¶ˆê· í˜• ë¬¸ì œê°€ ìˆìŒì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì–¸ë”/ ì˜¤ë²„ ìƒ˜í”Œë§ ê³¼ì •ì„ í†µí•œ ê²°ê³¼ë„ í™•ì¸í•˜ì—¬ ë†’ì€ ìŠ¤ì½”ì–´ë¥¼ ì„ íƒí•˜ë„ë¡ í•˜ì˜€ìŠµë‹ˆë‹¤.

![íšŒê³„_ë°ì´í„°ë¶„í¬](https://user-images.githubusercontent.com/31294995/134775057-84d31520-3b7a-455b-b51d-9453285a160b.PNG)

```python
#under sample
X_under, y_under = RandomUnderSampler(random_state=0).fit_resample(X_train, y_train)
# over sample
X_samp_smote, y_samp_smote = SMOTE(random_state=4).fit_resample(X_train, y_train)
```

### 3.1.1 Random Forest

1. Hyper Parameter Search   
```python
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]

random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}
               
rf = RandomForestClassifier()
rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)
rf_random.fit(X_train, y_train)
rf_random.best_params_
```
[ê·¸ë¦¼]

### 3.1.2 Xgboost

1. Hyper Parameter Search   
```python
min_child_weight =[1, 5, 10]
gamma = [0.5, 1, 1.5, 2, 5]
subsample = [0.6, 0.8, 1.0]
colsample_bytree = [0.6, 0.8, 1.0]
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
max_features = ['auto', 'sqrt']
max_depth = [3, 4, 5]
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]

random_grid = { 'n_estimators': n_estimators,
                'max_features': max_features,
                'max_depth': max_depth,
                'min_samples_split': min_samples_split,
                'min_samples_leaf': min_samples_leaf,
                'bootstrap': bootstrap,
                'min_child_weight' : min_child_weight,
                'gamma' : gamma,
                'subsample' :subsample,
                'colsample_bytree' : colsample_bytree}

xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='multi:softmax', silent=True, nthread=1)
xgb_random = RandomizedSearchCV(estimator = xgb, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)
xgb_random.fit(X_train, y_train)
xgb_random.best_params_ 
```
[ê·¸ë¦¼]

### 3.2 MLP


1. Parameter   
í•™ìŠµì„ ìœ„í•´ ì‚¬ìš©í•œ í•™ìŠµ íŒŒë¼ë¯¸í„°ë“¤ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python
EPOCHS = 50
BATCH_SIZE = 64
LEARNING_RATE = 0.001
NUM_FEATURES = len(X.columns)
NUM_CLASSES = 13
```

2. Network   
ë¶„ë¥˜ê¸° ë„¤íŠ¸ì›Œí¬ êµ¬ì„±ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.   
 
```python
# 3 Layer  
class MulticlassClassification(nn.Module):
    def __init__(self, num_feature, num_class):
        super(MulticlassClassification, self).__init__()
        
        self.layer_1 = nn.Linear(num_feature, 512)
        self.layer_2 = nn.Linear(512, 128)
        self.layer_3 = nn.Linear(128, 64)
        self.layer_out = nn.Linear(64, num_class) 
        
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.2)
        self.batchnorm1 = nn.BatchNorm1d(512)
        self.batchnorm2 = nn.BatchNorm1d(128)
        self.batchnorm3 = nn.BatchNorm1d(64)
        
    def forward(self, x):
        x = self.layer_1(x)
        x = self.batchnorm1(x)
        x = self.relu(x)
        
        x = self.layer_2(x)
        x = self.batchnorm2(x)
        x = self.relu(x)
        x = self.dropout(x)
        
        x = self.layer_3(x)
        x = self.batchnorm3(x)
        x = self.relu(x)
        x = self.dropout(x)
        
        x = self.layer_out(x)
        
        return x
```  

***
## 4 ìˆ˜í–‰ ê²°ê³¼

    ë¶„ë¥˜ ë¬¸ì œì´ê¸° ë•Œë¬¸ì— Confusion Matrixë¥¼ í†µí•´ ì‚°ì¶œëœ Accuracyë¥¼ í‰ê°€ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì•˜ìŠµë‹ˆë‹¤.

### Random Forest

### xgboost

1. Basic   
![íšŒê³„_basic](https://user-images.githubusercontent.com/31294995/134775328-4cb2304c-7f98-4dc3-87e5-8b80241f05d4.png)

2. Under Sampling   
![íšŒê³„_under](https://user-images.githubusercontent.com/31294995/134775326-3b2b7c31-f384-4089-8c60-b79726cd7409.png)

3. Over Sampling   
![íšŒê³„_over](https://user-images.githubusercontent.com/31294995/134775324-631a0098-fed4-440d-9c46-a6b964ae345d.png)

### MLP

1. train vs val Accuracy & Loss   
![íšŒê³„_mlp_train](https://user-images.githubusercontent.com/31294995/134775322-05fcfc07-272f-4af2-9767-9e8af4407dd9.PNG)

2. Confusion Matrix   
![mlp](https://user-images.githubusercontent.com/31294995/134775327-7ce65f6e-a6cd-4706-a8ef-7ef17ba2bf3a.png)

### Result
    XGBClassfierì™€ ê¸°ë³¸ ë°ì´í„°ë¥¼ í†µí•´ ë‚˜ì˜¨ 0.66ì„ Best ëª¨ë¸ë¡œ ì„ ì •í•˜ì˜€ìŠµë‹ˆë‹¤.
***
